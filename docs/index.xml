<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>patrolli</title>
    <link>https://patrolli.github.io/xssq/</link>
    <description>Recent content on patrolli</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Fri, 27 Aug 2021 13:39:18 +0800</lastBuildDate>
    
	<atom:link href="https://patrolli.github.io/xssq/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>pytorch geometric</title>
      <link>https://patrolli.github.io/xssq/post/pytorch_geometric/</link>
      <pubDate>Fri, 27 Aug 2021 13:39:18 +0800</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/pytorch_geometric/</guid>
      <description>Intro pytorch geometric 是基于 pytorch 的一个 GNN 框架库 安装 1 2 3 4 5 pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.7.0+${CUDA}.html pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.7.0+${CUDA}.html pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-1.7.0+${CUDA}.html pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.7.0+${CUDA}.html pip install torch-geometric 这里 ${CUDA} 根据对应的 cuda 版本选择：cpu, cu92, cu101, cu102, cu110 实验室 aimax</description>
    </item>
    
    <item>
      <title>GraphSAGE</title>
      <link>https://patrolli.github.io/xssq/post/graphsage/</link>
      <pubDate>Fri, 27 Aug 2021 11:50:05 +0800</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/graphsage/</guid>
      <description>pyg 中的实现 message propagation 的公式： 实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57</description>
    </item>
    
    <item>
      <title>PPDM: parallel point detection and matching for real-time human-object interaction detection</title>
      <link>https://patrolli.github.io/xssq/post/ppdm_parallel_point_detection_and_matching_for_real_time_human_object_interaction_detection/</link>
      <pubDate>Mon, 02 Aug 2021 00:00:00 +0800</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/ppdm_parallel_point_detection_and_matching_for_real_time_human_object_interaction_detection/</guid>
      <description>Motivation Method 总体框图 Point-dection 预测三种 box: human,object,intertion box. 每个 box 预测他们的中心点、size 以及偏移。对于中心点的预测，转换成 key-point estimation 的做法，将每个 ground truth 点转换成一个 heatmap, 然后预测的</description>
    </item>
    
    <item>
      <title>End-to-end object detection with transformers</title>
      <link>https://patrolli.github.io/xssq/post/carion-eccv-2020-end/</link>
      <pubDate>Thu, 15 Jul 2021 00:00:00 +0800</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/carion-eccv-2020-end/</guid>
      <description>Motivation 首篇将 transformer 用在 detection 任务上的工作 使用 transformer 来做 detection 任务，有什么优势的地方？ Method 总体架构是一个 encoder-decoder, 并且和之前的检测方法不同，DETR 可以直接输出对所有检测框</description>
    </item>
    
    <item>
      <title>Adaptive interaction modeling via graph operations search</title>
      <link>https://patrolli.github.io/xssq/post/li-cvpr-2020-adaptive/</link>
      <pubDate>Fri, 09 Jul 2021 00:00:00 +0800</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/li-cvpr-2020-adaptive/</guid>
      <description>Motivation 之前建模 action 中的 interaction 的工作都是设计了 fix 的 structure 来建模这些 interaction, 但视频中的 interction 具有不同的复杂性和特性，有些是场景的变化相关，有些是物体之间的复杂交互，所以</description>
    </item>
    
    <item>
      <title>Bipartite graph network with adaptive message passing for unbiased scene graph generation</title>
      <link>https://patrolli.github.io/xssq/post/li-cvpr-2021-bipartite/</link>
      <pubDate>Sun, 04 Jul 2021 00:00:00 +0800</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/li-cvpr-2021-bipartite/</guid>
      <description>Motivation Method Comment Ref </description>
    </item>
    
    <item>
      <title>Representing videos as discriminative sub-graphs for action recognition</title>
      <link>https://patrolli.github.io/xssq/post/li-cvpr-2021-representing/</link>
      <pubDate>Thu, 01 Jul 2021 00:00:00 +0800</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/li-cvpr-2021-representing/</guid>
      <description>Motivation 首先，视频中出现的不同 object 和 subject 可以看成是图的关系，对于不同的 action category, 图的结点数目可能是不一致的，因为一个视频的动作，有一些物体可能是和动作无关的</description>
    </item>
    
    <item>
      <title>Detecting Unseen Visual Relations Using Analogies</title>
      <link>https://patrolli.github.io/xssq/post/peyre-iccv-2019-detecting/</link>
      <pubDate>Wed, 19 May 2021 00:00:00 +0800</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/peyre-iccv-2019-detecting/</guid>
      <description>Motivation 直言要解决 HOI 中的组合问题：individual entities are available but their combinations are unseen at training. 之前的一些方法是单独检测 entity 和 predicate, 然后再把结果组合起来。但这样单独检测的问题</description>
    </item>
    
    <item>
      <title>Learning to detect human-object interactions with knowledge</title>
      <link>https://patrolli.github.io/xssq/post/xu-cvpr-2019-learning/</link>
      <pubDate>Tue, 18 May 2021 00:00:00 +0800</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/xu-cvpr-2019-learning/</guid>
      <description>Motivation 关注 HoI 的长尾分布问题 Motivation: HOIs contains intrinsic semantic regularities -&amp;gt; Modeling the underlying regularities among verbs and objects. Method 整体的框架： Knowledge graph 的构建：结点就是 HOI labels 中 verb 和 object 的词语，特征是 Glove 中得到的 semantic embedding. 结点的连接根据</description>
    </item>
    
    <item>
      <title>emacs counsel-find-file 快速输入目标路径</title>
      <link>https://patrolli.github.io/xssq/post/emacs_counsel_find_file_%E5%BF%AB%E9%80%9F%E8%BE%93%E5%85%A5%E7%9B%AE%E6%A0%87%E8%B7%AF%E5%BE%84/</link>
      <pubDate>Mon, 10 May 2021 00:00:00 +0800</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/emacs_counsel_find_file_%E5%BF%AB%E9%80%9F%E8%BE%93%E5%85%A5%E7%9B%AE%E6%A0%87%E8%B7%AF%E5%BE%84/</guid>
      <description>Intro 这个需求是最近用 xah-new-empty-buffer 来快速打开一个 buffer 记录一些草稿，然后保存文件，用它来代替 emacs 的 scratch buffer. 但一个问题是，在每次保存这些 untitled buffer 的时候 (c-x c-s), 默认打开的路径是</description>
    </item>
    
    <item>
      <title>pandoc</title>
      <link>https://patrolli.github.io/xssq/post/pandoc/</link>
      <pubDate>Thu, 06 May 2021 19:48:51 +0800</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/pandoc/</guid>
      <description>在将 org 文件导出成 word 的时候，文献的引用信息不能被导出，只好曲线救国，从 .tex 导出到 .docx. 命令如下： 1 pandoc -s foo.tex --bibliography=foo.bib --csl=ieee.csl -o foo.docx 这里需要指明 bib 文件的路径，另外需要单</description>
    </item>
    
    <item>
      <title>orgmode capture for project</title>
      <link>https://patrolli.github.io/xssq/post/orgmode_capture_for_project/</link>
      <pubDate>Tue, 27 Apr 2021 00:00:00 +0800</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/orgmode_capture_for_project/</guid>
      <description>Intro 为每一个 project 设置一个 org file, 将这个 project 相关的内容，如 idea, 日志，笔记等都放在一起。为了层次化这个 project org file, 我想使用 org-capture 来将每次要添加的内容，如日志或者 idea 添加</description>
    </item>
    
    <item>
      <title>org 整理 paper_index</title>
      <link>https://patrolli.github.io/xssq/post/org_%E6%95%B4%E7%90%86_paper_index/</link>
      <pubDate>Tue, 20 Apr 2021 00:21:19 +0800</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/org_%E6%95%B4%E7%90%86_paper_index/</guid>
      <description>Intro 花了一些时间用 elisp 写了一个函数，将 paper-index 中维护的论文索引按照他们的 tag 来进行分组。之前我是对每篇论文用一个一级 headline 进行维护，然后插入对应的 tag, 但这样做</description>
    </item>
    
    <item>
      <title>目录下 org 文件自动导出成 hugo md 文件</title>
      <link>https://patrolli.github.io/xssq/post/%E7%9B%AE%E5%BD%95%E4%B8%8B_org_%E6%96%87%E4%BB%B6%E8%87%AA%E5%8A%A8%E5%AF%BC%E5%87%BA%E6%88%90_hugo_md_%E6%96%87%E4%BB%B6/</link>
      <pubDate>Sat, 10 Apr 2021 00:37:09 +0800</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/%E7%9B%AE%E5%BD%95%E4%B8%8B_org_%E6%96%87%E4%BB%B6%E8%87%AA%E5%8A%A8%E5%AF%BC%E5%87%BA%E6%88%90_hugo_md_%E6%96%87%E4%BB%B6/</guid>
      <description>Intro 目前在从 org 使用 ox-hugo 导出成 hugo 的 blog 时，只能手动的执行 C-c C-e, 然后选择导出成 Hugo 形式的 markdown. 如果原始的 org 文件进行了修改，就需要每次自己手动去进行导出，有一些</description>
    </item>
    
    <item>
      <title>混合高斯分布</title>
      <link>https://patrolli.github.io/xssq/post/%E6%B7%B7%E5%90%88%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83/</link>
      <pubDate>Fri, 09 Apr 2021 19:46:59 +0800</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/%E6%B7%B7%E5%90%88%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83/</guid>
      <description></description>
    </item>
    
    <item>
      <title>hugo 博客搭建</title>
      <link>https://patrolli.github.io/xssq/post/hugo_%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/</link>
      <pubDate>Fri, 09 Apr 2021 19:46:58 +0800</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/hugo_%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/</guid>
      <description>基本安装与使用 Hugo 安装 直接在官网下载 Hugo 的安装包 本地创建 根据官网的 quick start, 创建一个 site 只需如下几个命令 1 hugo server 部署到 github pages github pages 有两种形式，一种是针对用户的</description>
    </item>
    
    <item>
      <title>ubuntu 安装 iosevka 字体</title>
      <link>https://patrolli.github.io/xssq/post/ubuntu_%E5%AE%89%E8%A3%85_iosevka_%E5%AD%97%E4%BD%93/</link>
      <pubDate>Fri, 09 Apr 2021 19:46:58 +0800</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/ubuntu_%E5%AE%89%E8%A3%85_iosevka_%E5%AD%97%E4%BD%93/</guid>
      <description>从 github 的代码仓库中下载 zip 文件，放到一个临时目录中 (&amp;ldquo;~/temp/&amp;quot;) 解压文件 1 unzip -u ttf-iosevka-5.2.1.zip -d iosevka 放到系统的字体目录： 1 sudo cp -r ~/temp/iosevka /usr/share/fonts/ 重新刷新字体缓存 1 fc-cache -fv Ref: Linux notes | Shreyas Ragavan</description>
    </item>
    
    <item>
      <title>Decaug: augmenting HOI detection via decomposition</title>
      <link>https://patrolli.github.io/xssq/post/xie-aaai-2021-decaug/</link>
      <pubDate>Fri, 09 Apr 2021 19:46:57 +0800</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/xie-aaai-2021-decaug/</guid>
      <description>Xie-aaai-2021-decaug Motivation 设计一种数据增强的方法 (pixel-level)，来增加 interaction 的 diversity, 以此缓解 HOI 中存在的长尾分布问题。通过贴图组合的方式来增加每种 HOI 的训练样本，</description>
    </item>
    
    <item>
      <title>EM算法</title>
      <link>https://patrolli.github.io/xssq/post/em%E7%AE%97%E6%B3%95/</link>
      <pubDate>Fri, 09 Apr 2021 19:46:57 +0800</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/em%E7%AE%97%E6%B3%95/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ffmpeg</title>
      <link>https://patrolli.github.io/xssq/post/ffmpeg/</link>
      <pubDate>Fri, 09 Apr 2021 19:46:57 +0800</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/ffmpeg/</guid>
      <description>使用 ffmpeg 将一系列帧图片转换成 .gif 和 .avi 1 2 ffmpeg -f image2 -i frame%4d.jpg video.avi ffmpeg -i video.avi -t 5 out.gif 将视频转换成图片 1 ffmpeg -i ./video.webm ./video/image%d.jpg</description>
    </item>
    
    <item>
      <title>配置 emacs-rime</title>
      <link>https://patrolli.github.io/xssq/post/2021-02-17-18-48/</link>
      <pubDate>Wed, 17 Feb 2021 00:00:00 +0800</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/2021-02-17-18-48/</guid>
      <description>配置 emacs rime 安装 安装 librime, 其他系统参考：emacs-rime/INSTALLATION.org at master · DogLooksGood/emacs-rime sudo apt install librime-dev 安装 emacs rime rime 在 melpa 源中已经发布，故可以直接</description>
    </item>
    
    <item>
      <title>hugo&amp;org-mode&amp;ox-hugo 的博客工作流</title>
      <link>https://patrolli.github.io/xssq/post/hugo-workflow/</link>
      <pubDate>Thu, 11 Feb 2021 17:51:00 +0800</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/hugo-workflow/</guid>
      <description>两种工作流 ox-hugo 有两种 work-flow: 一种是 one-post-per-subtree, 另一种是 one-post-per-file. ox-hugo 起到的作用实际是将我们写的 org 文件导出成 md, 并且生成 hugo 需要的 md 头文件信息，例如： 1 2 3 4 5 6 +++ title = &amp;#34;hugo&amp;amp;org-mode&amp;amp;ox-hugo 的博</description>
    </item>
    
    <item>
      <title>Detecting human-object interactions via functional generalization</title>
      <link>https://patrolli.github.io/xssq/post/bansal-aaai-2020-detecting/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/bansal-aaai-2020-detecting/</guid>
      <description>Motivation HOI 任务中，所有可能的 HOI 会随着 object 和 predicates 的数目增长而指数性地增长，但数据集中的训练样本并不能提供全部可能的 HOI, 这导致 HOI label 会有长尾分布的问题。 功能相</description>
    </item>
    
  </channel>
</rss>