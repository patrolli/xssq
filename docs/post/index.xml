<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on patrolli</title>
    <link>https://patrolli.github.io/xssq/post/</link>
    <description>Recent content in Posts on patrolli</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 10 Jan 2022 17:27:26 +0800</lastBuildDate><atom:link href="https://patrolli.github.io/xssq/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>awesome human object interaction</title>
      <link>https://patrolli.github.io/xssq/post/awesome_human_object_interaction/</link>
      <pubDate>Mon, 10 Jan 2022 17:27:26 +0800</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/awesome_human_object_interaction/</guid>
      <description>Intro HoI 是 visual relation 的一个子任务，它对 human body 和 object understanding 的依赖性很强 Transformer based QPIC: query-based pairwise human-object interaction detection with image-wide contextual information 这篇是基于 DETR 做的, 它有什么改进或区别吗？ 推理是什么做的？ Mining the benefits of two-stage</description>
    </item>
    
    <item>
      <title>美化 org-mode</title>
      <link>https://patrolli.github.io/xssq/post/%E7%BE%8E%E5%8C%96_org_mode/</link>
      <pubDate>Tue, 04 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/%E7%BE%8E%E5%8C%96_org_mode/</guid>
      <description>将 org list 变成一个圆点 效果示意： (defvar xs-org-list-prettify nil &amp;#34;toggle org list prettify&amp;#34;) (defvar gkroam-org-list-re &amp;#34;^ *\\([0-9]+[).]\\|[*+-]\\) \\(\\[[ X-]\\] \\)?&amp;#34; &amp;#34;Org list bullet and checkbox regexp.&amp;#34;) (defun gkroam--fontify-org-checkbox (notation) &amp;#34;Highlight org checkbox with NOTATION.&amp;#34; (add-text-properties (match-beginning 2) (1- (match-end 2)) `(display ,notation))) (defun gkroam--fontify-org-list () &amp;#34;Highlight org list, including bullet and checkbox.&amp;#34; (with-silent-modifications (add-text-properties (match-beginning 1) (match-end 1) &amp;#39;(display &amp;#3</description>
    </item>
    
    <item>
      <title>Decaug: augmenting HOI detection via decomposition</title>
      <link>https://patrolli.github.io/xssq/post/xie-aaai-2021-decaug/</link>
      <pubDate>Mon, 20 Dec 2021 00:36:51 +0800</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/xie-aaai-2021-decaug/</guid>
      <description>Motivation 设计一种数据增强的方法 (pixel-level)，来增加 interaction 的 diversity, 以此缓解 HOI 中存在的长尾分布问题。通过贴图组合的方式来增加每种 HOI 的训练样本，论</description>
    </item>
    
    <item>
      <title>org 整理 paper_index</title>
      <link>https://patrolli.github.io/xssq/post/org_%E6%95%B4%E7%90%86_paper_index/</link>
      <pubDate>Sat, 18 Dec 2021 18:21:56 +0800</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/org_%E6%95%B4%E7%90%86_paper_index/</guid>
      <description>Intro 花了一些时间用 elisp 写了一个函数，将 paper-index 中维护的论文索引按照他们的 tag 来进行分组。之前我是对每篇论文用一个一级 headline 进行维护，然后插入对应的 tag, 但这样做</description>
    </item>
    
    <item>
      <title>elfeed 标记光标之前的 entry 全为已读</title>
      <link>https://patrolli.github.io/xssq/post/elfeed_%E6%A0%87%E8%AE%B0%E5%85%89%E6%A0%87%E4%B9%8B%E5%89%8D%E7%9A%84_entry_%E5%85%A8%E4%B8%BA%E5%B7%B2%E8%AF%BB/</link>
      <pubDate>Sat, 18 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/elfeed_%E6%A0%87%E8%AE%B0%E5%85%89%E6%A0%87%E4%B9%8B%E5%89%8D%E7%9A%84_entry_%E5%85%A8%E4%B8%BA%E5%B7%B2%E8%AF%BB/</guid>
      <description>Intro elfeed 只有在 entry 上有 action 的才会标记为已读 (例如按 Enter 打开 entry, 用 b 在浏览器打开 entry 等). 但我很多时候只有扫一眼 entry 标题，不感兴趣的也就不会进一步点开了。这些</description>
    </item>
    
    <item>
      <title>crontab</title>
      <link>https://patrolli.github.io/xssq/post/crontab/</link>
      <pubDate>Sat, 11 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/crontab/</guid>
      <description></description>
    </item>
    
    <item>
      <title>定时同步 org 文件夹</title>
      <link>https://patrolli.github.io/xssq/post/%E5%AE%9A%E6%97%B6%E5%90%8C%E6%AD%A5_org_%E6%96%87%E4%BB%B6%E5%A4%B9/</link>
      <pubDate>Sat, 11 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/%E5%AE%9A%E6%97%B6%E5%90%8C%E6%AD%A5_org_%E6%96%87%E4%BB%B6%E5%A4%B9/</guid>
      <description>步骤 在 emacs 配置里面设置：(run-at-time &amp;quot;00:59&amp;quot; 3600 &#39;org-save-all-org-buffers). 每一个小时将所有打开的 org mode buffer 保存一次 用一个脚本来 commit org 的仓库： #!/bin/sh # Add org file changes to the repository REPOS=&amp;#34;org&amp;#34; for REPO in $REPOS</description>
    </item>
    
    <item>
      <title>emacs 的文献管理</title>
      <link>https://patrolli.github.io/xssq/post/emacs_%E7%9A%84%E6%96%87%E7%8C%AE%E7%AE%A1%E7%90%86/</link>
      <pubDate>Mon, 29 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/emacs_%E7%9A%84%E6%96%87%E7%8C%AE%E7%AE%A1%E7%90%86/</guid>
      <description>搜集 bib 在 emacs 中，可以通过 dblp-lookup 输入论文标题名来得到 bibtex 信息，然后手动复制粘贴到自己的 .bib 文件中。如果查询不到，就直接从 Google scholar, arxiv 上面复制 bibtex 信息。 可以用 bu-make-field-keywords 对</description>
    </item>
    
    <item>
      <title>cones</title>
      <link>https://patrolli.github.io/xssq/post/normal_cone/</link>
      <pubDate>Sun, 28 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/normal_cone/</guid>
      <description>Cone 锥 Convex cone 凸锥 Polar cone 定义: 从下面这个图可以看到，polar cone 类似于对集合 C 取反了 (这里需要 C 满足什么性质吗？如 convex set?)。 Tanget cone 对于给出的集合，</description>
    </item>
    
    <item>
      <title>awesome action recognition</title>
      <link>https://patrolli.github.io/xssq/post/awesome_action_recognition/</link>
      <pubDate>Mon, 18 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/awesome_action_recognition/</guid>
      <description>Egocentric Interactive Prototype Learning for Egocentric Action Recognition Epic-Kitchen 的数据集，将识别动作分解成识别 verb 和 noun. 文章首先得到 verb 的 prototype (verb classifier 权重的 l2 normalization), 然后用这个 prototype 去和 3D feature map 的所有 grid (TxHxW) vector 计算响应，来得到与动</description>
    </item>
    
    <item>
      <title>pytorch ddp</title>
      <link>https://patrolli.github.io/xssq/post/pytorch_ddp/</link>
      <pubDate>Mon, 20 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/pytorch_ddp/</guid>
      <description>一些基本术语 假设有两台机器，每台机器 8 张显卡，那么我们共有 16 张显卡，可以启动 16 个进程。 world_size: 全局的并行数，这里就是 16 rank: 表示当前进程的序号，对于 world_size=16</description>
    </item>
    
    <item>
      <title>python classmethod 和 staticmethod</title>
      <link>https://patrolli.github.io/xssq/post/python_classmethod_%E5%92%8C_staticmethod/</link>
      <pubDate>Sun, 19 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/python_classmethod_%E5%92%8C_staticmethod/</guid>
      <description>Intro 在 stackoverflow 上看到讲解 staticmethod 和 classmethod 之间区别的回答，翻译整理一下。 对于 classmethod 修饰的函数，必须接收一个 class object 作为第一个参数，而 staticmethod 可以不带参数。用一个具体的例子说明</description>
    </item>
    
    <item>
      <title>Towards compositional action recognition with spatio-temporal graph neural network</title>
      <link>https://patrolli.github.io/xssq/post/xie-arxiv-2021-towards/</link>
      <pubDate>Tue, 07 Sep 2021 13:50:42 +0800</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/xie-arxiv-2021-towards/</guid>
      <description>Motivation 将动作中的每一帧看作一个 scene graph, 通过这个 scene graph 可以得到动作中物体和人之间的交互关系，将这些 intermediate 的关系组合到一起，再去识别动作，这在 Ji-cvpr-2020-action 中被提出。 这篇</description>
    </item>
    
    <item>
      <title>hugo 博客文件缺失</title>
      <link>https://patrolli.github.io/xssq/post/hugo_%E5%8D%9A%E5%AE%A2%E6%96%87%E4%BB%B6%E7%BC%BA%E5%A4%B1/</link>
      <pubDate>Tue, 07 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/hugo_%E5%8D%9A%E5%AE%A2%E6%96%87%E4%BB%B6%E7%BC%BA%E5%A4%B1/</guid>
      <description>Intro 在发布 hugo 博客的时候遇到一个问题，当文件导出到 post 目录，部署到 github pages 后，网页没有把新的文章刷新出来。之前大概等 10 几秒就能够刷新。在 github 仓库的提交历</description>
    </item>
    
    <item>
      <title>emacs 在 org-mode 中补全符号</title>
      <link>https://patrolli.github.io/xssq/post/emacs_%E5%9C%A8_org_mode_%E4%B8%AD%E8%A1%A5%E5%85%A8%E7%AC%A6%E5%8F%B7/</link>
      <pubDate>Mon, 06 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/emacs_%E5%9C%A8_org_mode_%E4%B8%AD%E8%A1%A5%E5%85%A8%E7%AC%A6%E5%8F%B7/</guid>
      <description>Intro 在 abo-abo 的博客里翻倒一篇博文，将 completion-at-point 用到 org-mode 中，来补全引用内容 (即被 == 包围的内容). 这样，如果这个 symbol 在文档里面会重复多次，就不必每次都完整地输入 symbol,</description>
    </item>
    
    <item>
      <title>pytorch geometric</title>
      <link>https://patrolli.github.io/xssq/post/pytorch_geometric/</link>
      <pubDate>Fri, 27 Aug 2021 13:39:18 +0800</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/pytorch_geometric/</guid>
      <description>Intro pytorch geometric 是基于 pytorch 的一个 GNN 框架库 安装 pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.7.0+${CUDA}.html pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.7.0+${CUDA}.html pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-1.7.0+${CUDA}.html pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.7.0+${CUDA}.html pip install torch-geometric 这里 ${CUDA} 根据对应的 cuda 版本选择：cpu, cu92, cu101, cu102, cu110 实验室 aimax 上的 cuda 版本</description>
    </item>
    
    <item>
      <title>GraphSAGE</title>
      <link>https://patrolli.github.io/xssq/post/graphsage/</link>
      <pubDate>Fri, 27 Aug 2021 11:50:05 +0800</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/graphsage/</guid>
      <description>pyg 中的实现 message propagation 的公式： 实现 from typing import Union, Tuple from torch_geometric.typing import OptPairTensor, Adj, Size from torch import Tensor import torch from torch.nn import Linear import torch.nn.functional as F from torch_sparse import SparseTensor, matmul from torch_geometric.nn.conv import MessagePassing class SAGEConv(MessagePassing): def __init__(self, in_channels: Union[int, Tuple[int, int]], out_channels: int, normalize: bool = False, root_weight: bool = True, bias: bool = True, **kwargs):</description>
    </item>
    
    <item>
      <title>elfeed</title>
      <link>https://patrolli.github.io/xssq/post/elfeed/</link>
      <pubDate>Fri, 27 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/elfeed/</guid>
      <description>为 entry 设置星标 使用 Emacs 阅读邮件与 RSS - Emacs-general - Emacs China my/elfeed-toggle-star 设置代理</description>
    </item>
    
    <item>
      <title>Beta-Binomial共轭</title>
      <link>https://patrolli.github.io/xssq/post/beta_binomial%E5%85%B1%E8%BD%AD/</link>
      <pubDate>Mon, 23 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/beta_binomial%E5%85%B1%E8%BD%AD/</guid>
      <description>问题背景 推导： 这个问题的物理含义是什么？ 似乎可以对应贝叶斯推断： 形式</description>
    </item>
    
    <item>
      <title>Evidential deep learning</title>
      <link>https://patrolli.github.io/xssq/post/evidential_deep_learning/</link>
      <pubDate>Thu, 19 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/evidential_deep_learning/</guid>
      <description>对于一个 K 类的分类任务，EDL 将输入 x 看作一个命题，然后给出 K-维领域的主观意见 {1,&amp;hellip;,K}. 每一个主观意见被表示为一个三元组：(b, u, a). b 表示 belief mass, u 表</description>
    </item>
    
    <item>
      <title>Evidential deep learning for open set action recognition</title>
      <link>https://patrolli.github.io/xssq/post/evidential_deep_learning_for_open_set_action_recognition/</link>
      <pubDate>Thu, 19 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/evidential_deep_learning_for_open_set_action_recognition/</guid>
      <description>Motivation open-set action recognition 的挑战是什么？ static bias 带来的影响，将具有相同 static bias, 但不同 dynamic 的 unknown class 看作了 known class 去预测。 Method 为什么用狄利克雷分布来描述？ 主要内容： 使用 EDL 的 objective function, 学习</description>
    </item>
    
    <item>
      <title>PPDM: parallel point detection and matching for real-time human-object interaction detection</title>
      <link>https://patrolli.github.io/xssq/post/ppdm_parallel_point_detection_and_matching_for_real_time_human_object_interaction_detection/</link>
      <pubDate>Mon, 02 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/ppdm_parallel_point_detection_and_matching_for_real_time_human_object_interaction_detection/</guid>
      <description>Motivation Method 总体框图 Point-dection 预测三种 box: human,object,intertion box. 每个 box 预测他们的中心点、size 以及偏移。对于中心点的预测，转换成 key-point estimation 的做法，将每个 ground truth 点转换成一个 heatmap, 然后预测的</description>
    </item>
    
    <item>
      <title>End-to-end object detection with transformers</title>
      <link>https://patrolli.github.io/xssq/post/carion-eccv-2020-end/</link>
      <pubDate>Thu, 15 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/carion-eccv-2020-end/</guid>
      <description>Motivation 首篇将 transformer 用在 detection 任务上的工作 使用 transformer 来做 detection 任务，有什么优势的地方？ Method 总体架构是一个 encoder-decoder, 并且和之前的检测方法不同，DETR 可以直接输出对所有检测框</description>
    </item>
    
    <item>
      <title>Adaptive interaction modeling via graph operations search</title>
      <link>https://patrolli.github.io/xssq/post/li-cvpr-2020-adaptive/</link>
      <pubDate>Fri, 09 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/li-cvpr-2020-adaptive/</guid>
      <description>Motivation 之前建模 action 中的 interaction 的工作都是设计了 fix 的 structure 来建模这些 interaction, 但视频中的 interction 具有不同的复杂性和特性，有些是场景的变化相关，有些是物体之间的复杂交互，所以</description>
    </item>
    
    <item>
      <title>Bipartite graph network with adaptive message passing for unbiased scene graph generation</title>
      <link>https://patrolli.github.io/xssq/post/li-cvpr-2021-bipartite/</link>
      <pubDate>Sun, 04 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/li-cvpr-2021-bipartite/</guid>
      <description>Motivation Method Comment Ref </description>
    </item>
    
    <item>
      <title>Representing videos as discriminative sub-graphs for action recognition</title>
      <link>https://patrolli.github.io/xssq/post/li-cvpr-2021-representing/</link>
      <pubDate>Thu, 01 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/li-cvpr-2021-representing/</guid>
      <description>Motivation 首先，视频中出现的不同 object 和 subject 可以看成是图的关系，对于不同的 action category, 图的结点数目可能是不一致的，因为一个视频的动作，有一些物体可能是和动作无关的</description>
    </item>
    
    <item>
      <title>图的匹配</title>
      <link>https://patrolli.github.io/xssq/post/%E5%9B%BE%E7%9A%84%E5%8C%B9%E9%85%8D/</link>
      <pubDate>Thu, 27 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/%E5%9B%BE%E7%9A%84%E5%8C%B9%E9%85%8D/</guid>
      <description>定义 M 是图 G 的边子集（不含自环），且 M 中的任意两条边没有共同顶点，则称 M 是 G 的一个匹配 如果 G 中顶点 v 是 G 的匹配 M 中某条边的端点，则称它为 M 饱</description>
    </item>
    
    <item>
      <title>Detecting Unseen Visual Relations Using Analogies</title>
      <link>https://patrolli.github.io/xssq/post/peyre-iccv-2019-detecting/</link>
      <pubDate>Wed, 19 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/peyre-iccv-2019-detecting/</guid>
      <description>Motivation 直言要解决 HOI 中的组合问题：individual entities are available but their combinations are unseen at training. 之前的一些方法是单独检测 entity 和 predicate, 然后再把结果组合起来。但这样单独检测的问题</description>
    </item>
    
    <item>
      <title>Learning to detect human-object interactions with knowledge</title>
      <link>https://patrolli.github.io/xssq/post/xu-cvpr-2019-learning/</link>
      <pubDate>Tue, 18 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/xu-cvpr-2019-learning/</guid>
      <description>Motivation 关注 HoI 的长尾分布问题 Motivation: HOIs contains intrinsic semantic regularities -&amp;gt; Modeling the underlying regularities among verbs and objects. Method 整体的框架： Knowledge graph 的构建：结点就是 HOI labels 中 verb 和 object 的词语，特征是 Glove 中得到的 semantic embedding. 结点的连接根据</description>
    </item>
    
    <item>
      <title>emacs counsel-find-file 快速输入目标路径</title>
      <link>https://patrolli.github.io/xssq/post/emacs_counsel_find_file_%E5%BF%AB%E9%80%9F%E8%BE%93%E5%85%A5%E7%9B%AE%E6%A0%87%E8%B7%AF%E5%BE%84/</link>
      <pubDate>Mon, 10 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/emacs_counsel_find_file_%E5%BF%AB%E9%80%9F%E8%BE%93%E5%85%A5%E7%9B%AE%E6%A0%87%E8%B7%AF%E5%BE%84/</guid>
      <description>Intro 这个需求是最近用 xah-new-empty-buffer 来快速打开一个 buffer 记录一些草稿，然后保存文件，用它来代替 emacs 的 scratch buffer. 但一个问题是，在每次保存这些 untitled buffer 的时候 (c-x c-s), 默认打开的路径是</description>
    </item>
    
    <item>
      <title>pandoc</title>
      <link>https://patrolli.github.io/xssq/post/pandoc/</link>
      <pubDate>Thu, 06 May 2021 19:48:51 +0800</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/pandoc/</guid>
      <description>在将 org 文件导出成 word 的时候，文献的引用信息不能被导出，只好曲线救国，从 .tex 导出到 .docx. 命令如下： pandoc -s foo.tex --bibliography=foo.bib --csl=ieee.csl -o foo.docx 这里需要指明 bib 文件的路径，另外需要单独</description>
    </item>
    
    <item>
      <title>orgmode capture for project</title>
      <link>https://patrolli.github.io/xssq/post/orgmode_capture_for_project/</link>
      <pubDate>Tue, 27 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/orgmode_capture_for_project/</guid>
      <description>Intro 为每一个 project 设置一个 org file, 将这个 project 相关的内容，如 idea, 日志，笔记等都放在一起。为了层次化这个 project org file, 我想使用 org-capture 来将每次要添加的内容，如日志或者 idea 添加</description>
    </item>
    
    <item>
      <title>目录下 org 文件自动导出成 hugo md 文件</title>
      <link>https://patrolli.github.io/xssq/post/%E7%9B%AE%E5%BD%95%E4%B8%8B_org_%E6%96%87%E4%BB%B6%E8%87%AA%E5%8A%A8%E5%AF%BC%E5%87%BA%E6%88%90_hugo_md_%E6%96%87%E4%BB%B6/</link>
      <pubDate>Sat, 10 Apr 2021 00:37:09 +0800</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/%E7%9B%AE%E5%BD%95%E4%B8%8B_org_%E6%96%87%E4%BB%B6%E8%87%AA%E5%8A%A8%E5%AF%BC%E5%87%BA%E6%88%90_hugo_md_%E6%96%87%E4%BB%B6/</guid>
      <description>Intro 目前在从 org 使用 ox-hugo 导出成 hugo 的 blog 时，只能手动的执行 C-c C-e, 然后选择导出成 Hugo 形式的 markdown. 如果原始的 org 文件进行了修改，就需要每次自己手动去进行导出，有一些</description>
    </item>
    
    <item>
      <title>混合高斯分布</title>
      <link>https://patrolli.github.io/xssq/post/%E6%B7%B7%E5%90%88%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83/</link>
      <pubDate>Fri, 09 Apr 2021 19:46:59 +0800</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/%E6%B7%B7%E5%90%88%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ubuntu 安装 iosevka 字体</title>
      <link>https://patrolli.github.io/xssq/post/ubuntu_%E5%AE%89%E8%A3%85_iosevka_%E5%AD%97%E4%BD%93/</link>
      <pubDate>Fri, 09 Apr 2021 19:46:58 +0800</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/ubuntu_%E5%AE%89%E8%A3%85_iosevka_%E5%AD%97%E4%BD%93/</guid>
      <description>从 github 的代码仓库中下载 zip 文件，放到一个临时目录中 (&amp;quot;~/temp/&amp;quot;) 解压文件 unzip -u ttf-iosevka-5.2.1.zip -d iosevka 放到系统的字体目录： sudo cp -r ~/temp/iosevka /usr/share/fonts/ 重新刷新字体缓存 fc-cache -fv Ref: Linux notes | Shreyas Ragavan</description>
    </item>
    
    <item>
      <title>EM算法</title>
      <link>https://patrolli.github.io/xssq/post/em%E7%AE%97%E6%B3%95/</link>
      <pubDate>Fri, 09 Apr 2021 19:46:57 +0800</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/em%E7%AE%97%E6%B3%95/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ffmpeg</title>
      <link>https://patrolli.github.io/xssq/post/ffmpeg/</link>
      <pubDate>Fri, 09 Apr 2021 19:46:57 +0800</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/ffmpeg/</guid>
      <description>使用 ffmpeg 将一系列帧图片转换成 .gif 和 .avi ffmpeg -f image2 -i frame%4d.jpg video.avi ffmpeg -i video.avi -t 5 out.gif 将视频转换成图片 ffmpeg -i ./video.webm ./video/image%d.jpg</description>
    </item>
    
    <item>
      <title>配置 emacs-rime</title>
      <link>https://patrolli.github.io/xssq/post/2021-02-17-18-48/</link>
      <pubDate>Wed, 17 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/2021-02-17-18-48/</guid>
      <description>配置 emacs rime 安装 安装 librime, 其他系统参考：emacs-rime/INSTALLATION.org at master · DogLooksGood/emacs-rime sudo apt install librime-dev 安装 emacs rime rime 在 melpa 源中已经发布，故可以直接</description>
    </item>
    
    <item>
      <title>hugo&amp;org-mode&amp;ox-hugo 的博客工作流</title>
      <link>https://patrolli.github.io/xssq/post/hugo-workflow/</link>
      <pubDate>Thu, 11 Feb 2021 17:51:00 +0800</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/hugo-workflow/</guid>
      <description>两种工作流 ox-hugo 有两种 work-flow: 一种是 one-post-per-subtree, 另一种是 one-post-per-file. ox-hugo 起到的作用实际是将我们写的 org 文件导出成 md, 并且生成 hugo 需要的 md 头文件信息，例如： +++ title = &amp;#34;hugo&amp;amp;org-mode&amp;amp;ox-hugo 的博客工作流&amp;#</description>
    </item>
    
    <item>
      <title>hugo 博客搭建</title>
      <link>https://patrolli.github.io/xssq/post/hugo_%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/</link>
      <pubDate>Thu, 11 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/hugo_%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/</guid>
      <description>基本配置 Hugo 安装 直接在官网下载 Hugo 的安装包 本地创建 根据官网的 quick start, 创建一个 site 只需如下几个命令 hugo server 部署到 github pages github pages 有两种形式，一种是针对用户的 pages: &amp;lt</description>
    </item>
    
    <item>
      <title>Detecting human-object interactions via functional generalization</title>
      <link>https://patrolli.github.io/xssq/post/bansal-aaai-2020-detecting/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://patrolli.github.io/xssq/post/bansal-aaai-2020-detecting/</guid>
      <description>Motivation HOI 任务中，所有可能的 HOI 会随着 object 和 predicates 的数目增长而指数性地增长，但数据集中的训练样本并不能提供全部可能的 HOI, 这导致 HOI label 会有长尾分布的问题。 功能相</description>
    </item>
    
  </channel>
</rss>
